{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(f'{PATH}folketinget/20091.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncate the text when just testing stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mødet er åbnet.I dag er der følgende anmeldelser: Thor Pedersen (V), Mogens Lykketoft (S), Søren Espersen (DF), Holger K. Nielsen (SF) og Helge Adam Møller (KF):Lovforslag nr. L 53 (Forslag til lov om ændring af valg til Folketinget. (Ændring af reglerne om boliger til folketingsmedlemmer m.v.)).Ministeren for sundhed og forebyggelse (Jakob Axel Nielsen): Lovforslag nr. L 54 (Forslag til lov om æn'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\x00\\t\\n !'(),-./0123456789:;?ABCDEFGHIJKLMNOPRSTUVWY[]abcdefghijklmnopqrstuvwxyz§«²»½ÅÆØåæéø–’…\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping between chars and indices, and reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = { c: i for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_char = { i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_indices['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 87, 53, 54, 69, 3, 54, 67, 3, 84]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char_indices[c] for c in text[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F', 'G', 'H']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[i] for i in [30, 31, 32]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use indices as data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [ char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 87, 53, 54, 69, 3, 54, 67, 3, 84]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'ø', 'd', 'e', 't', ' ', 'e', 'r', ' ', 'å', 'b', 'n', 'e', 't']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[i] for i in idx[:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [idx[i    ] for i in range(0, len(idx) - cs, cs)]\n",
    "c2_dat = [idx[i + 1] for i in range(0, len(idx) - cs, cs)]\n",
    "c3_dat = [idx[i + 2] for i in range(0, len(idx) - cs, cs)]\n",
    "c4_dat = [idx[i + 3] for i in range(0, len(idx) - cs, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first characters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'e', 'e', 'å']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[indices_char[c] for c in c1_dat[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37, 54, 54, 84]), array([87, 69, 67, 51]), array([53,  3,  3, 63]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((333333,), (333333,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size())).cuda()\n",
    "        h = F.tanh(self.l_hidden(h + in1))\n",
    "        h = F.tanh(self.l_hidden(h + in2))\n",
    "        h = F.tanh(self.l_hidden(h + in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Char3Model(\n",
       "  (e): Embedding(91, 42)\n",
       "  (l_in): Linear(in_features=42, out_features=256, bias=True)\n",
       "  (l_hidden): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (l_out): Linear(in_features=256, out_features=91, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Char3Model(vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1, x2, x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Char3Model(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs, yt = next(it)\n",
    "len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 54\n",
       " 68\n",
       " 61\n",
       " 54\n",
       " 58\n",
       " 10\n",
       " 69\n",
       " 55\n",
       " 71\n",
       " 53\n",
       " 68\n",
       " 69\n",
       " 54\n",
       " 69\n",
       " 61\n",
       " 58\n",
       " 68\n",
       " 63\n",
       " 54\n",
       " 68\n",
       " 54\n",
       "  3\n",
       " 69\n",
       " 59\n",
       " 54\n",
       " 65\n",
       " 56\n",
       " 67\n",
       " 60\n",
       " 61\n",
       " 63\n",
       " 54\n",
       " 10\n",
       " 67\n",
       " 62\n",
       " 68\n",
       "  3\n",
       " 85\n",
       "  3\n",
       " 55\n",
       " 54\n",
       "  3\n",
       " 54\n",
       " 63\n",
       " 54\n",
       " 60\n",
       " 63\n",
       " 85\n",
       " 67\n",
       " 63\n",
       " 53\n",
       "  3\n",
       " 68\n",
       " 56\n",
       " 69\n",
       " 62\n",
       " 57\n",
       " 53\n",
       " 63\n",
       " 64\n",
       " 85\n",
       " 63\n",
       " 58\n",
       " 50\n",
       " 54\n",
       "  3\n",
       " 61\n",
       " 70\n",
       "  3\n",
       "  3\n",
       " 61\n",
       " 54\n",
       "  8\n",
       "  3\n",
       " 54\n",
       " 63\n",
       " 63\n",
       " 71\n",
       " 63\n",
       " 56\n",
       " 53\n",
       " 64\n",
       " 50\n",
       " 53\n",
       " 55\n",
       " 58\n",
       " 58\n",
       " 54\n",
       " 63\n",
       " 56\n",
       " 69\n",
       " 63\n",
       " 67\n",
       " 55\n",
       "  3\n",
       "  3\n",
       " 70\n",
       "  3\n",
       "  3\n",
       " 67\n",
       " 28\n",
       " 58\n",
       " 74\n",
       " 53\n",
       " 54\n",
       " 10\n",
       "  3\n",
       "  3\n",
       " 55\n",
       " 54\n",
       " 53\n",
       "  3\n",
       " 50\n",
       "  8\n",
       " 50\n",
       "  3\n",
       "  3\n",
       "  3\n",
       " 63\n",
       " 61\n",
       " 54\n",
       " 50\n",
       " 58\n",
       " 54\n",
       " 87\n",
       " 59\n",
       " 56\n",
       " 61\n",
       " 54\n",
       " 53\n",
       " 63\n",
       " 50\n",
       " 50\n",
       " 54\n",
       "  3\n",
       "  3\n",
       " 54\n",
       " 69\n",
       " 58\n",
       " 84\n",
       " 69\n",
       " 87\n",
       " 51\n",
       " 58\n",
       " 28\n",
       "  3\n",
       "  3\n",
       " 60\n",
       " 54\n",
       " 63\n",
       " 63\n",
       " 68\n",
       " 53\n",
       " 69\n",
       " 64\n",
       " 62\n",
       " 61\n",
       " 56\n",
       " 69\n",
       " 56\n",
       " 54\n",
       "  3\n",
       " 71\n",
       " 54\n",
       " 50\n",
       " 55\n",
       " 54\n",
       " 87\n",
       " 59\n",
       " 50\n",
       " 84\n",
       " 61\n",
       " 53\n",
       " 54\n",
       "  3\n",
       "  3\n",
       "  3\n",
       " 57\n",
       " 62\n",
       " 68\n",
       "  3\n",
       " 67\n",
       " 54\n",
       "  3\n",
       "  3\n",
       " 58\n",
       " 67\n",
       " 64\n",
       " 60\n",
       " 50\n",
       "  3\n",
       " 69\n",
       " 62\n",
       " 61\n",
       " 68\n",
       "  3\n",
       " 10\n",
       " 67\n",
       " 55\n",
       " 10\n",
       " 58\n",
       " 58\n",
       "  3\n",
       " 54\n",
       "  3\n",
       " 28\n",
       " 54\n",
       " 71\n",
       "  3\n",
       " 50\n",
       " 50\n",
       " 63\n",
       " 51\n",
       " 58\n",
       " 71\n",
       " 58\n",
       " 58\n",
       " 55\n",
       " 53\n",
       "  3\n",
       "  3\n",
       "  3\n",
       " 71\n",
       " 58\n",
       " 54\n",
       " 50\n",
       " 64\n",
       " 54\n",
       "  3\n",
       " 64\n",
       "  3\n",
       "  3\n",
       " 87\n",
       "  3\n",
       " 55\n",
       "  3\n",
       " 69\n",
       "  3\n",
       "  3\n",
       "  3\n",
       " 55\n",
       " 61\n",
       " 56\n",
       " 85\n",
       " 68\n",
       " 54\n",
       " 58\n",
       " 50\n",
       " 53\n",
       " 58\n",
       " 61\n",
       " 60\n",
       "  3\n",
       "  3\n",
       " 52\n",
       " 69\n",
       " 56\n",
       " 69\n",
       "  3\n",
       " 68\n",
       "  3\n",
       " 70\n",
       " 58\n",
       " 53\n",
       " 58\n",
       " 63\n",
       " 63\n",
       " 51\n",
       " 67\n",
       "  8\n",
       " 60\n",
       " 71\n",
       " 67\n",
       " 54\n",
       " 55\n",
       " 84\n",
       " 50\n",
       "  3\n",
       " 59\n",
       "  3\n",
       " 58\n",
       " 54\n",
       " 54\n",
       " 61\n",
       " 68\n",
       " 50\n",
       " 60\n",
       " 71\n",
       " 68\n",
       " 67\n",
       "  3\n",
       " 63\n",
       " 50\n",
       " 54\n",
       " 69\n",
       " 67\n",
       "  8\n",
       " 30\n",
       " 54\n",
       " 64\n",
       " 68\n",
       " 67\n",
       " 65\n",
       " 71\n",
       "  3\n",
       " 60\n",
       "  3\n",
       " 69\n",
       "  3\n",
       " 54\n",
       " 67\n",
       "  3\n",
       " 53\n",
       "  3\n",
       " 55\n",
       " 70\n",
       " 59\n",
       "  3\n",
       "  3\n",
       "  8\n",
       " 68\n",
       " 69\n",
       " 65\n",
       " 50\n",
       " 56\n",
       " 54\n",
       " 58\n",
       " 60\n",
       "  3\n",
       " 53\n",
       " 61\n",
       " 50\n",
       " 56\n",
       " 54\n",
       "  3\n",
       " 54\n",
       " 54\n",
       " 54\n",
       " 54\n",
       "  3\n",
       " 50\n",
       " 60\n",
       "  3\n",
       " 54\n",
       " 54\n",
       " 67\n",
       " 54\n",
       " 51\n",
       "  8\n",
       " 58\n",
       " 50\n",
       " 54\n",
       " 56\n",
       " 67\n",
       " 71\n",
       " 69\n",
       " 61\n",
       " 53\n",
       "  3\n",
       "  3\n",
       " 56\n",
       " 50\n",
       " 54\n",
       " 54\n",
       " 63\n",
       " 61\n",
       " 54\n",
       " 71\n",
       "  3\n",
       " 67\n",
       " 69\n",
       " 53\n",
       "  3\n",
       " 56\n",
       " 50\n",
       "  3\n",
       "  3\n",
       " 67\n",
       "  3\n",
       " 63\n",
       " 68\n",
       " 63\n",
       " 84\n",
       " 54\n",
       " 61\n",
       " 63\n",
       " 54\n",
       "  3\n",
       " 58\n",
       " 54\n",
       " 62\n",
       " 56\n",
       " 58\n",
       "  3\n",
       " 57\n",
       " 53\n",
       "  3\n",
       " 54\n",
       "  3\n",
       " 71\n",
       " 50\n",
       " 55\n",
       " 67\n",
       " 52\n",
       " 63\n",
       " 71\n",
       "  3\n",
       " 50\n",
       " 71\n",
       " 67\n",
       " 70\n",
       " 50\n",
       " 69\n",
       " 60\n",
       " 67\n",
       " 54\n",
       " 63\n",
       " 68\n",
       " 61\n",
       "  3\n",
       " 61\n",
       " 54\n",
       " 64\n",
       " 67\n",
       " 69\n",
       " 64\n",
       " 54\n",
       " 84\n",
       " 63\n",
       " 58\n",
       " 58\n",
       " 57\n",
       " 64\n",
       "  3\n",
       " 54\n",
       " 54\n",
       " 63\n",
       " 62\n",
       " 58\n",
       " 54\n",
       " 55\n",
       " 58\n",
       " 68\n",
       " 58\n",
       " 54\n",
       " 50\n",
       " 60\n",
       "  3\n",
       "  3\n",
       " 58\n",
       " 71\n",
       " 67\n",
       " 71\n",
       "  3\n",
       " 61\n",
       " 60\n",
       " 71\n",
       " 60\n",
       " 63\n",
       " 51\n",
       " 67\n",
       "  3\n",
       " 62\n",
       "  3\n",
       " 68\n",
       "  3\n",
       " 53\n",
       " 67\n",
       " 61\n",
       " 51\n",
       " 64\n",
       " 87\n",
       " 51\n",
       " 50\n",
       " 65\n",
       " 69\n",
       " 54\n",
       " 69\n",
       "  3\n",
       " 64\n",
       "  3\n",
       " 64\n",
       " 58\n",
       " 84\n",
       "  3\n",
       " 69\n",
       " 87\n",
       " 50\n",
       " 54\n",
       "  3\n",
       " 67\n",
       " 53\n",
       " 61\n",
       "  3\n",
       " 63\n",
       " 69\n",
       " 56\n",
       " 61\n",
       " 69\n",
       " 60\n",
       " 68\n",
       " 71\n",
       "  8\n",
       "  3\n",
       " 53\n",
       " 69\n",
       " 58\n",
       " 68\n",
       "  3\n",
       " 54\n",
       " 64\n",
       " 58\n",
       "[torch.cuda.LongTensor of size 512 (GPU 0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d2b4c987934204949a5da561ce7245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.843705   0.425638  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.42564])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27606ee363a45549cb82eb2d46bb306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.615591   0.222878  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.22288])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    idx = np.argmax(to_np(p))\n",
    "    return indices_char[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Fol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Soc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('Min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more(inp, length):\n",
    "    next = inp\n",
    "    while len(next) < length:\n",
    "        next += get_next(next[-3:])\n",
    "    return next     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'skatte er det er det er det er det er det er det e'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_more('skat', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.h = V(torch.zeros(n_hidden)).cuda()\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        self.h = F.tanh(self.l_hidden(self.h + in1))\n",
    "        self.h = F.tanh(self.l_hidden(self.h + in2))\n",
    "        self.h = F.tanh(self.l_hidden(self.h + in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(self.h))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Char3Model2(vocab_size, n_fac).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22277eb72de4393a0602799cd21165a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/652 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-8e1cb7e8a6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/courses/dl1/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
